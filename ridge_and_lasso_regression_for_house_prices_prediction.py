# -*- coding: utf-8 -*-
"""Ridge and Lasso Regression for House Prices Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ZBPp4rC2VIHfO1kF89T0o0E8ibWsQSj

# PREDICTING THE HOUSE PRICES USING RIDGE AND LASSO REGRESSION

# DATA REVIEW

- Data Source: https://www.kaggle.com/harlfoxem/housesalesprediction
- Dataset includes house sale prices for King County in USA. 
- Homes that are sold in the time period: May, 2014 and May, 2015.

- Columns:
    - ida: notation for a house
    - date: Date house was sold
    - price: Price is prediction target
    - bedrooms: Number of Bedrooms/House
    - bathrooms: Number of bathrooms/House
    - sqft_living: square footage of the home
    - sqft_lot: square footage of the lot
    - floors: Total floors (levels) in house
    - waterfront: House which has a view to a waterfront
    - view: Has been viewed
    - condition: How good the condition is ( Overall )
    - grade: overall grade given to the housing unit, based on King County grading system
    - sqft_abovesquare: footage of house apart from basement
    - sqft_basement: square footage of the basement
    - yr_built: Built Year
    - yr_renovated: Year when house was renovated
    - zipcode: zip
    - lat: Latitude coordinate
    - long: Longitude coordinate
    - sqft_living15: Living room area in 2015(implies-- some renovations) 
    - sqft_lot15: lotSize area in 2015(implies-- some renovations)

#  I. LIBRARIES
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

"""# II. DATASET"""

house_df = pd.read_csv('kc_house_data.csv', encoding = 'ISO-8859-1')

house_df.head()

house_df.describe()

house_df.info()

"""# III. VISUALIZATION"""

house_df.keys()

sns.scatterplot(x = 'bedrooms', y = 'price', data = house_df)

sns.scatterplot(x = 'sqft_living', y = 'price', data = house_df)

sns.scatterplot(x = 'sqft_lot', y = 'price', data = house_df)

house_df.hist(bins=20,figsize=(20,20), color = 'r')

f, ax = plt.subplots(figsize=(20, 20))
sns.heatmap(house_df.corr(), annot = True)

sns.pairplot(house_df)

# pick a sample of the data
house_df_sample =house_df[['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'yr_built']]

sns.pairplot(house_df_sample)

"""# IV. CREATING TESTING AND TRAINING DATASET/DATA CLEANING"""

selected_features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors', 'sqft_above', 'sqft_basement', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'yr_built', 
'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']

X = house_df[selected_features]

X.shape

y = house_df['price']

y.shape

"""# V. TRAINING THE MODEL"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

from sklearn.linear_model import LinearRegression

regressor = LinearRegression(fit_intercept =True)
regressor.fit(X_train,y_train)
print('Linear Model Coefficient (m): ', regressor.coef_)
print('Linear Model Coefficient (b): ', regressor.intercept_)

"""# VI. MODEL EVALUATION

# LINEAR REGRESSION
"""

y_predict_linear = regressor.predict( X_test)
y_predict_linear

plt.plot(y_test, y_predict_linear, "^", color = 'r')
plt.xlim(0, 3000000)
plt.ylim(0, 3000000)

plt.xlabel("Model Predictions")
plt.ylabel("True Value (ground Truth)")
plt.title('Linear Regression Predictions')
plt.show()

k = X_test.shape[1]
n = len(X_test)

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt
y_predict = y_predict_linear
RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))
MSE = mean_squared_error(y_test, y_predict)
MAE = mean_absolute_error(y_test, y_predict)
r2 = r2_score(y_test, y_predict)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('LINEAR:','\nRMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)

"""# RIDGE REGRESSION"""

from sklearn.linear_model import Lasso, Ridge

regressor_ridge = Ridge(alpha = 50) # alpha zmienia nachylenie prostej
regressor_ridge.fit(X_train, y_train)
print('Linear Model Coefficient (m): ', regressor_ridge.coef_)
print('Linear Model Coefficient (b): ', regressor_ridge.intercept_)

y_predict_ridge = regressor_ridge.predict( X_test)
y_predict_ridge

plt.plot(y_test, y_predict_ridge, "^", color = 'b')
plt.xlim(0, 3000000)
plt.ylim(0, 3000000)

plt.xlabel("Model Predictions")
plt.ylabel("True Value (ground Truth)")
plt.title('Ridge Regression Predictions')
plt.show()

y_predict = y_predict_ridge
RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))
MSE = mean_squared_error(y_test, y_predict)
MAE = mean_absolute_error(y_test, y_predict)
r2 = r2_score(y_test, y_predict)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('RIDGE:','\nRMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)

"""# LASSO REGRESSION"""

from sklearn.linear_model import Lasso

regressor_lasso = Lasso(alpha = 500)
regressor_lasso.fit(X_train,y_train)
print('Linear Model Coefficient (m): ', regressor_lasso.coef_)
print('Linear Model Coefficient (b): ', regressor_lasso.intercept_)

y_predict_lasso = regressor_lasso.predict( X_test)
y_predict_lasso

plt.plot(y_test, y_predict_lasso, "^", color = 'brown')
plt.xlim(0, 3000000)
plt.ylim(0, 3000000)

plt.xlabel("Model Predictions")
plt.ylabel("True Value (ground Truth)")
plt.title('Lasso Regression Predictions')
plt.show()

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt

y_predict=y_predict_lasso
RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))
MSE = mean_squared_error(y_test, y_predict)
MAE = mean_absolute_error(y_test, y_predict)
r2 = r2_score(y_test, y_predict)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('LASSO:','\nRMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)